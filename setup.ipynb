{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ddafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "from utils.data_transform import Sentinel2Transform\n",
    "from utils.sentinel_2_reader import S2Reader\n",
    "from utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils import train_valid_eval_utils as tveu\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3824ff2",
   "metadata": {},
   "source": [
    "# Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiant_mlhub import Dataset\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = '380ab1acf08f82cddc417ddaf61b6acbaceb0e6a125435e63b79d93efe0110c6'\n",
    "\n",
    "if not os.path.exists('data/'):\n",
    "    os.makedirs('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.fetch('dlr_fusion_competition_germany')\n",
    "print(f'{dataset.id}: {dataset.title}')\n",
    "dataset.download('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def189ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'\n",
    "brandenburg_te_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_test_labels/dlr_fusion_competition_germany_test_labels_33N_17E_243N/vector_labels.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd037948",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_tr_labels=gpd.read_file(brandenburg_tr_labels_dir)\n",
    "print('INFO: Number of fields: {}\\n'.format(len(brandenburg_tr_labels)))\n",
    "brandenburg_tr_labels.info()\n",
    "brandenburg_tr_labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids=brandenburg_tr_labels['crop_id'].unique()\n",
    "label_names=brandenburg_tr_labels['crop_name'].unique()\n",
    "\n",
    "print('INFO: Label IDs: {}'.format(label_ids))\n",
    "print('INFO: Label Names: {}'.format(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts=brandenburg_tr_labels['crop_name'].value_counts()\n",
    "\n",
    "colors_list = ['#78C850','#A8B820','#F8D030','#E0C068', '#F08030', '#C03028', '#F85888','#6890F0','#98D8D8'] \n",
    "ax=value_counts.plot.bar(color=colors_list)\n",
    "ax.set_ylabel(\"Number of Fields\")\n",
    "ax.set_xlabel(\"Crop Types\")\n",
    "\n",
    "print('INFO: Number of Fields by Crop Type: \\n{}'.format(value_counts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf9763b7",
   "metadata": {},
   "source": [
    "# Exploring S2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12391026",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_s2_train_dir = \"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973eb503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZE THE DATA READER TO OBSERVE THE FIELDS FROM PLANET DATA: \n",
    "\n",
    "# Choose some days of the year to plot\n",
    "selected_data_indices = range(143) #beware that S2 data is not daily, \n",
    "\n",
    "#Initialize data reader for planet images\n",
    "s2_reader = S2Reader(input_dir=brandenburg_s2_train_dir,\n",
    "                                  label_dir=brandenburg_tr_labels_dir,\n",
    "                                  selected_time_points=selected_data_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37c80a72",
   "metadata": {},
   "source": [
    "# Working with Sentinel 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23260d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_s2_train_dir = \"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/\"\n",
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(\"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/fid_210180.npz\")\n",
    "\n",
    "# Check the available data indices\n",
    "print(data.files)\n",
    "# available_indices = data['image_stack']\n",
    "print(len(data['image_stack']))\n",
    "# print(\"Available data indices:\", available_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75370b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_color(X):\n",
    "    blue = X[1]/(X[1].max()/255.0)\n",
    "    green = X[2]/(X[2].max()/255.0)\n",
    "    red = X[3]/(X[3].max()/255.0)\n",
    "    tc = np.dstack((red,green,blue)) \n",
    "    \n",
    "    return tc.astype('uint8')\n",
    "\n",
    "def ndvi(X):\n",
    "    red = X[3]\n",
    "    nir = X[7]\n",
    "    return (nir-red) / (nir + red)\n",
    "\n",
    "def endvi(X):\n",
    "    B8 = X[7]\n",
    "    B4 = X[3]\n",
    "    B2 = X[1]\n",
    "    return 2.5 * ((B8 - B4) / (B8 + 6 * B4 - 7.5 * B2 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38baef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected_time_interval can be left empty to exploit all available time points\n",
    "s2_reader = S2Reader(input_dir=brandenburg_s2_train_dir, label_dir=brandenburg_tr_labels_dir)\n",
    "\n",
    "crop_id, crop_name = label_ids[7], label_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a013615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Median value of each field for all days\n",
    "median = []\n",
    "days = []\n",
    "iterable = iter(s2_reader)\n",
    "while True:\n",
    "    X, y, mask, _ = next(iterable)\n",
    "\n",
    "    width = X.shape[-1]\n",
    "    height = X.shape[-2]\n",
    "\n",
    "    if y == crop_id and width > 60 and height > 60:\n",
    "        for day in range(143):\n",
    "            median.append(np.median(ndvi(X[day])))\n",
    "            days.append(day)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(days, median)\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "887c1961",
   "metadata": {},
   "source": [
    "# Preparing Sentinel 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8669e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_s2_train_dir = \"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/\"\n",
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'\n",
    "\n",
    "brandenburg_tr_labels=gpd.read_file(brandenburg_tr_labels_dir)\n",
    "label_ids=brandenburg_tr_labels['crop_id'].unique()\n",
    "label_names=brandenburg_tr_labels['crop_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_lists = zip(label_ids, label_names)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "\n",
    "tuples = zip(*sorted_pairs)\n",
    "label_ids, label_names = [ list(tuple) for tuple in  tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_2_transformer=Sentinel2Transform()\n",
    "s2_reader = S2Reader(input_dir=brandenburg_s2_train_dir, label_dir=brandenburg_tr_labels_dir, label_ids=label_ids, transform=sentinel_2_transformer.transform, min_area_to_ignore=1000)\n",
    "\n",
    "data_loader=DataLoader(train_val_reader=s2_reader, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bf8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=data_loader.get_train_loader(batch_size=8, num_workers=1)\n",
    "valid_loader=data_loader.get_validation_loader(batch_size=8, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7cc1b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f2dbbe4",
   "metadata": {},
   "source": [
    "# CNN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9be503fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: model initialized with name:Conv3d_LSTM_222222\n",
      "CNNLSTM(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm): LSTM(2, 9, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import importlib\n",
    "\n",
    "importlib.reload(models)\n",
    "\n",
    "INPUT_DIM = 2\n",
    "DEVICE = 'cuda'\n",
    "#sequence lenth = 144 total?\n",
    "SEQUENCE_LENGTH=140\n",
    "START_EPOCH=0\n",
    "TOTAL_EPOCH=1\n",
    "\n",
    "# models.test()\n",
    "\n",
    "brandenburg_model = models.CNNLSTM(input_dim=INPUT_DIM, num_classes=len(label_ids), device=DEVICE)\n",
    "print(brandenburg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a24dfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(brandenburg_model.parameters(), lr=1e-3, momentum=0.9,nesterov=False)\n",
    "loss_criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a69d972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging results will be saved to temp_s2/Conv3d_LSTM_222222\n"
     ]
    }
   ],
   "source": [
    "# Logging results\n",
    "log = list()\n",
    "log_root='temp_s2/'\n",
    "logdir = os.path.join(log_root, brandenburg_model.modelname)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "print(\"INFO: Logging results will be saved to {}\".format(logdir))\n",
    "summarywriter = SummaryWriter(log_dir=logdir)\n",
    "snapshot_path = os.path.join(logdir, \"model.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7e457caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training if stopped midway ?\n",
    "snapshot_path = os.path.join(logdir, \"model.pth.tar\")\n",
    "if os.path.exists(snapshot_path):\n",
    "    checkpoint = torch.load(snapshot_path)\n",
    "    START_EPOCH = checkpoint[\"epoch\"]\n",
    "    log = checkpoint[\"log\"]\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    brandenburg_model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    print(f\"INFO: Resuming from {snapshot_path}, epoch {START_EPOCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f2bc4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_28612\\98819779.py\", line 2, in <module>\n",
      "    train_loss = tveu.train_epoch(brandenburg_model, optimizer, loss_criterion, train_loader, device=DEVICE)\n",
      "  File \"c:\\Users\\kevin\\Documents\\MSc Dissertation\\utils\\train_valid_eval_utils.py\", line 97, in train_epoch\n",
      "    loss = criterion(model.forward(x.to(device)), y_true.to(device))\n",
      "  File \"c:\\Users\\kevin\\Documents\\MSc Dissertation\\models.py\", line 116, in forward\n",
      "    x = self.fc(x)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1502, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x9 and 64x9)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\kevin\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, TOTAL_EPOCH):\n",
    "    train_loss = tveu.train_epoch(brandenburg_model, optimizer, loss_criterion, train_loader, device=DEVICE)\n",
    "    valid_loss, y_true, y_pred, *_ = tveu.validation_epoch(brandenburg_model, loss_criterion, valid_loader, device=DEVICE)\n",
    "    \n",
    "    \n",
    "    scores = tveu.metrics(y_true.cpu(), y_pred.cpu())\n",
    "    \n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores.items()])\n",
    "    \n",
    "    valid_loss = valid_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "\n",
    "    scores[\"epoch\"] = epoch\n",
    "    scores[\"train_loss\"] = train_loss\n",
    "    scores[\"valid_loss\"] = valid_loss\n",
    "    log.append(scores)\n",
    "\n",
    "    summarywriter.add_scalars(\"losses\", dict(train=train_loss, valid=valid_loss), global_step=epoch)\n",
    "    summarywriter.add_scalars(\"metrics\",\n",
    "                              {key: scores[key] for key in\n",
    "                               ['accuracy', 'kappa', 'f1_micro', 'f1_macro', 'f1_weighted', \n",
    "                                'recall_micro','recall_macro', 'recall_weighted', \n",
    "                                'precision_micro', 'precision_macro','precision_weighted']},\n",
    "                                global_step=epoch)\n",
    "\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred.cpu().detach().numpy(), labels=np.arange(len(label_ids)))\n",
    "    summarywriter.add_figure(\"confusion_matrix\",tveu.confusion_matrix_figure(cm, labels=label_ids),global_step=epoch)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(os.path.join(logdir, \"train_log.csv\"))\n",
    "\n",
    "    torch.save(dict( model_state=brandenburg_model.state_dict(),optimizer_state=optimizer.state_dict(), epoch=epoch, log=log),snapshot_path)\n",
    "    if len(log) > 2:\n",
    "        if valid_loss < np.array([l[\"valid_loss\"] for l in log[:-1]]).min():\n",
    "            best_model = snapshot_path.replace(\"model.pth.tar\",\"model_best.pth.tar\")\n",
    "            print(f\"INFO: New best model with valid_loss {valid_loss:.2f} at {best_model}\")\n",
    "            shutil.copy(snapshot_path, best_model)\n",
    "\n",
    "    print(f\"INFO: epoch {epoch}: train_loss {train_loss:.2f}, valid_loss {valid_loss:.2f} \" + scores_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
