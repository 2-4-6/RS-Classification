{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ddafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "from utils.data_transform import Sentinel2Transform\n",
    "from utils.sentinel_2_reader import S2Reader\n",
    "from utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7593b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils import train_valid_eval_utils as tveu\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiant_mlhub import Dataset\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = '380ab1acf08f82cddc417ddaf61b6acbaceb0e6a125435e63b79d93efe0110c6'\n",
    "\n",
    "if not os.path.exists('data/'):\n",
    "    os.makedirs('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5275115e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfetch(\u001b[39m'\u001b[39m\u001b[39mdlr_fusion_competition_germany\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39mtitle\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m dataset\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.fetch('dlr_fusion_competition_germany')\n",
    "print(f'{dataset.id}: {dataset.title}')\n",
    "dataset.download('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def189ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'\n",
    "brandenburg_te_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_test_labels/dlr_fusion_competition_germany_test_labels_33N_17E_243N/vector_labels.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd037948",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_tr_labels=gpd.read_file(brandenburg_tr_labels_dir)\n",
    "print('INFO: Number of fields: {}\\n'.format(len(brandenburg_tr_labels)))\n",
    "brandenburg_tr_labels.info()\n",
    "brandenburg_tr_labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids=brandenburg_tr_labels['crop_id'].unique()\n",
    "label_names=brandenburg_tr_labels['crop_name'].unique()\n",
    "\n",
    "print('INFO: Label IDs: {}'.format(label_ids))\n",
    "print('INFO: Label Names: {}'.format(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts=brandenburg_tr_labels['crop_name'].value_counts()\n",
    "\n",
    "colors_list = ['#78C850','#A8B820','#F8D030','#E0C068', '#F08030', '#C03028', '#F85888','#6890F0','#98D8D8'] \n",
    "ax=value_counts.plot.bar(color=colors_list)\n",
    "ax.set_ylabel(\"Number of Fields\")\n",
    "ax.set_xlabel(\"Crop Types\")\n",
    "\n",
    "print('INFO: Number of Fields by Crop Type: \\n{}'.format(value_counts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37c80a72",
   "metadata": {},
   "source": [
    "# Working with Sentinel 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23260d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_s2_train_dir = \"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/\"\n",
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(\"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/fid_3935.npz\")\n",
    "\n",
    "# Check the available data indices\n",
    "available_indices = data['image_stack']\n",
    "print(len(data['image_stack']))\n",
    "print(\"Available data indices:\", available_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75370b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_color(X):\n",
    "    blue = X[1]/(X[1].max()/255.0)\n",
    "    green = X[2]/(X[2].max()/255.0)\n",
    "    red = X[3]/(X[3].max()/255.0)\n",
    "    tc = np.dstack((red,green,blue)) \n",
    "    \n",
    "    return tc.astype('uint8')\n",
    "\n",
    "def ndvi(X):\n",
    "    red = X[3]\n",
    "    nir = X[7]\n",
    "    return (nir-red) / (nir + red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38baef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected_time_interval can be left empty to exploit all available time points\n",
    "s2_reader = S2Reader(input_dir=brandenburg_s2_train_dir, label_dir=brandenburg_tr_labels_dir)\n",
    "\n",
    "crop_id, crop_name = label_ids[7], label_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a013615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Median value of each field for all days\n",
    "median = []\n",
    "days = []\n",
    "iterable = iter(s2_reader)\n",
    "while True:\n",
    "    X, y, mask, _ = next(iterable)\n",
    "\n",
    "    width = X.shape[-1]\n",
    "    height = X.shape[-2]\n",
    "\n",
    "    if y == crop_id and width > 60 and height > 60:\n",
    "        for day in range(143):\n",
    "            median.append(np.median(ndvi(X[day])))\n",
    "            days.append(day)\n",
    "\n",
    "        break\n",
    "\n",
    "print(median)\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(days, median)\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "887c1961",
   "metadata": {},
   "source": [
    "# Preparing Sentinel 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8669e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandenburg_s2_train_dir = \"data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/\"\n",
    "brandenburg_tr_labels_dir='data/dlr_fusion_competition_germany/dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/vector_labels.geojson'\n",
    "\n",
    "brandenburg_tr_labels=gpd.read_file(brandenburg_tr_labels_dir)\n",
    "label_ids=brandenburg_tr_labels['crop_id'].unique()\n",
    "label_names=brandenburg_tr_labels['crop_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f6ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_lists = zip(label_ids, label_names)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "\n",
    "tuples = zip(*sorted_pairs)\n",
    "label_ids, label_names = [ list(tuple) for tuple in  tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65f3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Ignoring 30/2534 fields with area < 1000m2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Extracting time series into the folder: data\\dlr_fusion_competition_germany\\dlr_fusion_competition_germany_train_source_sentinel_2\\dlr_fusion_competition_germany_train_source_sentinel_2_33N_18E_242N_2018/: 100%|██████████| 2504/2504 [00:00<00:00, 8831.95it/s]\n"
     ]
    }
   ],
   "source": [
    "sentinel_2_transformer=Sentinel2Transform()\n",
    "s2_reader = S2Reader(input_dir=brandenburg_s2_train_dir, label_dir=brandenburg_tr_labels_dir, label_ids=label_ids, transform=sentinel_2_transformer.transform, min_area_to_ignore=1000)\n",
    "\n",
    "data_loader=DataLoader(train_val_reader=s2_reader, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0bf8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Training data loader initialized.\n",
      "INFO: Validation data loader initialized.\n"
     ]
    }
   ],
   "source": [
    "train_loader=data_loader.get_train_loader(batch_size=8, num_workers=1)\n",
    "valid_loader=data_loader.get_validation_loader(batch_size=8, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc1b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f2dbbe4",
   "metadata": {},
   "source": [
    "# CNN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be503fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: model initialized with name:Conv2d_LSTM\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import importlib\n",
    "\n",
    "importlib.reload(models)\n",
    "\n",
    "INPUT_DIM = 12\n",
    "#sequence lenth = 144 total?\n",
    "SEQUENCE_LENGTH=50\n",
    "DEVICE='cuda'\n",
    "START_EPOCH=0\n",
    "TOTAL_EPOCH=1\n",
    "\n",
    "# models.test()\n",
    "\n",
    "brandenburg_model = models.SpatiotemporalModel(input_dim=INPUT_DIM, num_classes=len(label_ids), sequencelength=SEQUENCE_LENGTH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a24dfeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(brandenburg_model.parameters(), lr=1e-3, momentum=0.9,nesterov=False)\n",
    "loss_criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a69d972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Logging results will be saved to temp_s2/Conv2d_LSTM\n"
     ]
    }
   ],
   "source": [
    "# Logging results\n",
    "log = list()\n",
    "log_root='temp_s2/'\n",
    "logdir = os.path.join(log_root, brandenburg_model.modelname)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "print(\"INFO: Logging results will be saved to {}\".format(logdir))\n",
    "summarywriter = SummaryWriter(log_dir=logdir)\n",
    "snapshot_path = os.path.join(logdir, \"model.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e457caf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m START_EPOCH \u001b[39m=\u001b[39m checkpoint[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m log \u001b[39m=\u001b[39m checkpoint[\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m optimizer\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39moptimizer_state\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      8\u001b[0m brandenburg_model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m\"\u001b[39m\u001b[39mmodel_state\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mINFO: Resuming from \u001b[39m\u001b[39m{\u001b[39;00msnapshot_path\u001b[39m}\u001b[39;00m\u001b[39m, epoch \u001b[39m\u001b[39m{\u001b[39;00mSTART_EPOCH\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:437\u001b[0m, in \u001b[0;36mOptimizer.load_state_dict\u001b[1;34m(self, state_dict)\u001b[0m\n\u001b[0;32m    435\u001b[0m saved_lens \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(g[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m saved_groups)\n\u001b[0;32m    436\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(p_len \u001b[39m!=\u001b[39m s_len \u001b[39mfor\u001b[39;00m p_len, s_len \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(param_lens, saved_lens)):\n\u001b[1;32m--> 437\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mloaded state dict contains a parameter group \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthat doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match the size of optimizer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms group\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[39m# Update the state\u001b[39;00m\n\u001b[0;32m    441\u001b[0m id_map \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(chain\u001b[39m.\u001b[39mfrom_iterable((g[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m saved_groups)),\n\u001b[0;32m    442\u001b[0m               chain\u001b[39m.\u001b[39mfrom_iterable((g[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m groups))))\n",
      "\u001b[1;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "# Resume training if stopped midway ?\n",
    "snapshot_path = os.path.join(logdir, \"model.pth.tar\")\n",
    "if os.path.exists(snapshot_path):\n",
    "    checkpoint = torch.load(snapshot_path)\n",
    "    START_EPOCH = checkpoint[\"epoch\"]\n",
    "    log = checkpoint[\"log\"]\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    brandenburg_model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    print(f\"INFO: Resuming from {snapshot_path}, epoch {START_EPOCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2bc4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "LSTM: Expected input to be 2-D or 3-D but received 5-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(START_EPOCH, TOTAL_EPOCH):\n\u001b[1;32m----> 2\u001b[0m     train_loss \u001b[39m=\u001b[39m tveu\u001b[39m.\u001b[39;49mtrain_epoch(brandenburg_model, optimizer, loss_criterion, train_loader, device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[0;32m      3\u001b[0m     valid_loss, y_true, y_pred, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m tveu\u001b[39m.\u001b[39mvalidation_epoch(brandenburg_model, loss_criterion, valid_loader, device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m      6\u001b[0m     scores \u001b[39m=\u001b[39m tveu\u001b[39m.\u001b[39mmetrics(y_true\u001b[39m.\u001b[39mcpu(), y_pred\u001b[39m.\u001b[39mcpu())\n",
      "File \u001b[1;32mc:\\Users\\kevin\\Documents\\MSc Dissertation\\utils\\train_valid_eval_utils.py:97\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[0;32m     95\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     96\u001b[0m x, y_true, _, _ \u001b[39m=\u001b[39m batch\n\u001b[1;32m---> 97\u001b[0m loss \u001b[39m=\u001b[39m criterion(model\u001b[39m.\u001b[39;49mforward(x\u001b[39m.\u001b[39;49mto(device)), y_true\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     98\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     99\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\Documents\\MSc Dissertation\\models.py:21\u001b[0m, in \u001b[0;36mSpatiotemporalModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     20\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_encoder(x)\n\u001b[1;32m---> 21\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemporal_encoder(x)\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kevin\\Documents\\MSc Dissertation\\models.py:51\u001b[0m, in \u001b[0;36mTemporalEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 51\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:799\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    797\u001b[0m         hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    798\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 799\u001b[0m     \u001b[39massert\u001b[39;00m (\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLSTM: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    800\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m    801\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: LSTM: Expected input to be 2-D or 3-D but received 5-D tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, TOTAL_EPOCH):\n",
    "    train_loss = tveu.train_epoch(brandenburg_model, optimizer, loss_criterion, train_loader, device=DEVICE)\n",
    "    valid_loss, y_true, y_pred, *_ = tveu.validation_epoch(brandenburg_model, loss_criterion, valid_loader, device=DEVICE)\n",
    "    \n",
    "    \n",
    "    scores = tveu.metrics(y_true.cpu(), y_pred.cpu())\n",
    "    \n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores.items()])\n",
    "    \n",
    "    valid_loss = valid_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "\n",
    "    scores[\"epoch\"] = epoch\n",
    "    scores[\"train_loss\"] = train_loss\n",
    "    scores[\"valid_loss\"] = valid_loss\n",
    "    log.append(scores)\n",
    "\n",
    "    summarywriter.add_scalars(\"losses\", dict(train=train_loss, valid=valid_loss), global_step=epoch)\n",
    "    summarywriter.add_scalars(\"metrics\",\n",
    "                              {key: scores[key] for key in\n",
    "                               ['accuracy', 'kappa', 'f1_micro', 'f1_macro', 'f1_weighted', \n",
    "                                'recall_micro','recall_macro', 'recall_weighted', \n",
    "                                'precision_micro', 'precision_macro','precision_weighted']},\n",
    "                                global_step=epoch)\n",
    "\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred.cpu().detach().numpy(), labels=np.arange(len(label_ids)))\n",
    "    summarywriter.add_figure(\"confusion_matrix\",tveu.confusion_matrix_figure(cm, labels=label_ids),global_step=epoch)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(os.path.join(logdir, \"train_log.csv\"))\n",
    "\n",
    "    torch.save(dict( model_state=brandenburg_model.state_dict(),optimizer_state=optimizer.state_dict(), epoch=epoch, log=log),snapshot_path)\n",
    "    if len(log) > 2:\n",
    "        if valid_loss < np.array([l[\"valid_loss\"] for l in log[:-1]]).min():\n",
    "            best_model = snapshot_path.replace(\"model.pth.tar\",\"model_best.pth.tar\")\n",
    "            print(f\"INFO: New best model with valid_loss {valid_loss:.2f} at {best_model}\")\n",
    "            shutil.copy(snapshot_path, best_model)\n",
    "\n",
    "    print(f\"INFO: epoch {epoch}: train_loss {train_loss:.2f}, valid_loss {valid_loss:.2f} \" + scores_msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca90bd5d",
   "metadata": {},
   "source": [
    "# Old Keras stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7cef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm = Sequential()\n",
    "cnn_lstm.add(TimeDistributed(Conv2D(64, kernel_size=(11, 11), strides=(4, 4), padding='same', input_shape=(None, None, 4))))\n",
    "cnn_lstm.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "cnn_lstm.add(TimeDistributed(Flatten()))\n",
    "\n",
    "cnn_lstm.add(LSTM(units = 9, input_shape=(None, 4)))\n",
    "cnn_lstm.add(Dense(9, activation='softmax'))\n",
    "\n",
    "cnn_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm.fit(generator(train_loader), epochs=1, validation_data=generator(valid_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
